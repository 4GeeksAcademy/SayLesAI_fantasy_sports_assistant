{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling\n",
    "\n",
    "Since the data tables on the [Footballguys](https://www.footballguys.com/) website are fully rendered in HTML, we might be able to scrape the data without too much trouble. This gives us good control over exactly what data we download and an easy mechanism by which to update it throughout the season. Let's give it a try using [urllib](https://docs.python.org/3/howto/urllib2.html) and [BeautifulSoup](https://beautiful-soup-4.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import urllib.request\n",
    "from itertools import product\n",
    "from random import randrange\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download and parse HTML data\n",
    "\n",
    "The available data spans 1996 to 2024 and each year has 18 weeks of data. We also will want to download the data for multiple positions. But, let's start with just one. We also need to pick a scoring scheme, let's go with PPR. We can easily change this later. We will use a loop to construct and download the URL for each year and week and parse and collect the data as we get it.\n",
    "\n",
    "**Note**: Downloading all of the data for one position takes just over 45 minutes.\n",
    "\n",
    "### 1.1. Download function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_url(url: str) -> bytes:\n",
    "    '''Takes string url, downloads URL and returns HTML bytes object'''\n",
    "\n",
    "    headers={\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Host\": \"httpbin.io\",\n",
    "        \"Sec-Ch-Ua\": '\"Google Chrome\";v=\"131\", \"Chromium\";v=\"131\", \"Not_A Brand\";v=\"24\"',\n",
    "        \"Sec-Ch-Ua-Mobile\": \"?0\",\n",
    "        \"Sec-Ch-Ua-Platform\": '\"Linux\"',\n",
    "        \"Sec-Fetch-Dest\": \"document\",\n",
    "        \"Sec-Fetch-Mode\": \"navigate\",\n",
    "        \"Sec-Fetch-Site\": \"cross-site\",\n",
    "        \"Sec-Fetch-User\": \"?1\",\n",
    "        \"Upgrade-Insecure-Requests\": \"1\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    # Create the request\n",
    "    request_params = urllib.request.Request(\n",
    "        url=url,\n",
    "        headers=headers\n",
    "    )   \n",
    "\n",
    "    # Get the html\n",
    "    with urllib.request.urlopen(request_params) as response:\n",
    "        html=response.read()\n",
    "\n",
    "    return html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. HTML parsing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html_table(html: bytes, year: int, week: int, position: str, profile: str) -> pd.DataFrame:\n",
    "    '''Takes a html bytes object from URL, parses data table, adds\n",
    "    year, week, position and scoring profile and returns as pandas dataframe'''\n",
    "\n",
    "    # Extract the table rows\n",
    "    soup=BeautifulSoup(html, 'html.parser')\n",
    "    table=soup.find('table',{'class':'datasmall table'})\n",
    "    table_rows=table.find_all('tr')\n",
    "\n",
    "    # Get the column names from the first row\n",
    "    columns=table_rows[0].find_all('th')\n",
    "    column_names=[column.getText() for column in columns]\n",
    "    column_names.extend(['Position', 'Year', 'Week', 'Scoring profile'])\n",
    "\n",
    "    # Get the values for each row\n",
    "    data=[]\n",
    "\n",
    "    for row in table_rows[1:]:\n",
    "        columns=row.find_all('td')\n",
    "        values=[column.getText() for column in columns]\n",
    "        values.extend([position, year, week, profile])\n",
    "        data.append(values)\n",
    "\n",
    "    # Convert to pandas dataframe and return\n",
    "    return pd.DataFrame(columns=column_names, data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Main download loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading QB, 2020, week 1\n",
      "Downloading QB, 2020, week 2\n",
      "Downloading QB, 2020, week 3\n",
      "Downloading QB, 2020, week 4\n",
      "Downloading QB, 2020, week 5\n",
      "Downloading QB, 2020, week 6\n",
      "Downloading QB, 2020, week 7\n",
      "Downloading QB, 2020, week 8\n",
      "Downloading QB, 2020, week 9\n",
      "Downloading QB, 2020, week 10\n",
      "Downloading QB, 2020, week 11\n",
      "Downloading QB, 2020, week 12\n",
      "Downloading QB, 2020, week 13\n",
      "Downloading QB, 2020, week 14\n",
      "Downloading QB, 2020, week 15\n",
      "Downloading QB, 2020, week 16\n",
      "Downloading QB, 2020, week 17\n",
      "Downloading QB, 2020, week 18\n",
      "Downloading QB, 2021, week 1\n",
      "Downloading QB, 2021, week 2\n",
      "Downloading QB, 2021, week 3\n",
      "Downloading QB, 2021, week 4\n",
      "Downloading QB, 2021, week 5\n",
      "Downloading QB, 2021, week 6\n",
      "Downloading QB, 2021, week 7\n",
      "Downloading QB, 2021, week 8\n",
      "Downloading QB, 2021, week 9\n",
      "Downloading QB, 2021, week 10\n",
      "Downloading QB, 2021, week 11\n",
      "Downloading QB, 2021, week 12\n",
      "Downloading QB, 2021, week 13\n",
      "Downloading QB, 2021, week 14\n",
      "Downloading QB, 2021, week 15\n",
      "Downloading QB, 2021, week 16\n",
      "Downloading QB, 2021, week 17\n",
      "Downloading QB, 2021, week 18\n",
      "Downloading QB, 2022, week 1\n",
      "Downloading QB, 2022, week 2\n",
      "Downloading QB, 2022, week 3\n",
      "Downloading QB, 2022, week 4\n",
      "Downloading QB, 2022, week 5\n",
      "Downloading QB, 2022, week 6\n",
      "Downloading QB, 2022, week 7\n",
      "Downloading QB, 2022, week 8\n",
      "Downloading QB, 2022, week 9\n",
      "Downloading QB, 2022, week 10\n",
      "Downloading QB, 2022, week 11\n",
      "Downloading QB, 2022, week 12\n",
      "Downloading QB, 2022, week 13\n",
      "Downloading QB, 2022, week 14\n",
      "Downloading QB, 2022, week 15\n",
      "Downloading QB, 2022, week 16\n",
      "Downloading QB, 2022, week 17\n",
      "Downloading QB, 2022, week 18\n",
      "Downloading QB, 2023, week 1\n",
      "Downloading QB, 2023, week 2\n",
      "Downloading QB, 2023, week 3\n",
      "Downloading QB, 2023, week 4\n",
      "Downloading QB, 2023, week 5\n",
      "Downloading QB, 2023, week 6\n",
      "Downloading QB, 2023, week 7\n",
      "Downloading QB, 2023, week 8\n",
      "Downloading QB, 2023, week 9\n",
      "Downloading QB, 2023, week 10\n",
      "Downloading QB, 2023, week 11\n",
      "Downloading QB, 2023, week 12\n",
      "Downloading QB, 2023, week 13\n",
      "Downloading QB, 2023, week 14\n",
      "Downloading QB, 2023, week 15\n",
      "Downloading QB, 2023, week 16\n",
      "Downloading QB, 2023, week 17\n",
      "Downloading QB, 2023, week 18\n",
      "Downloading RB, 2020, week 1\n",
      "Downloading RB, 2020, week 2\n",
      "Downloading RB, 2020, week 3\n",
      "Downloading RB, 2020, week 4\n",
      "Downloading RB, 2020, week 5\n",
      "Downloading RB, 2020, week 6\n",
      "Downloading RB, 2020, week 7\n",
      "Downloading RB, 2020, week 8\n",
      "Downloading RB, 2020, week 9\n",
      "Downloading RB, 2020, week 10\n",
      "Downloading RB, 2020, week 11\n",
      "Downloading RB, 2020, week 12\n",
      "Downloading RB, 2020, week 13\n",
      "Downloading RB, 2020, week 14\n",
      "Downloading RB, 2020, week 15\n",
      "Downloading RB, 2020, week 16\n",
      "Downloading RB, 2020, week 17\n",
      "Downloading RB, 2020, week 18\n",
      "Downloading RB, 2021, week 1\n",
      "Downloading RB, 2021, week 2\n",
      "Downloading RB, 2021, week 3\n",
      "Downloading RB, 2021, week 4\n",
      "Downloading RB, 2021, week 5\n",
      "Downloading RB, 2021, week 6\n",
      "Downloading RB, 2021, week 7\n",
      "Downloading RB, 2021, week 8\n",
      "Downloading RB, 2021, week 9\n",
      "Downloading RB, 2021, week 10\n",
      "Downloading RB, 2021, week 11\n",
      "Downloading RB, 2021, week 12\n",
      "Downloading RB, 2021, week 13\n",
      "Downloading RB, 2021, week 14\n",
      "Downloading RB, 2021, week 15\n",
      "Downloading RB, 2021, week 16\n",
      "Downloading RB, 2021, week 17\n",
      "Downloading RB, 2021, week 18\n",
      "Downloading RB, 2022, week 1\n",
      "Downloading RB, 2022, week 2\n",
      "Downloading RB, 2022, week 3\n",
      "Downloading RB, 2022, week 4\n",
      "Downloading RB, 2022, week 5\n",
      "Downloading RB, 2022, week 6\n",
      "Downloading RB, 2022, week 7\n",
      "Downloading RB, 2022, week 8\n",
      "Downloading RB, 2022, week 9\n",
      "Downloading RB, 2022, week 10\n",
      "Downloading RB, 2022, week 11\n",
      "Downloading RB, 2022, week 12\n",
      "Downloading RB, 2022, week 13\n",
      "Downloading RB, 2022, week 14\n",
      "Downloading RB, 2022, week 15\n",
      "Downloading RB, 2022, week 16\n",
      "Downloading RB, 2022, week 17\n",
      "Downloading RB, 2022, week 18\n",
      "Downloading RB, 2023, week 1\n",
      "Downloading RB, 2023, week 2\n",
      "Downloading RB, 2023, week 3\n",
      "Downloading RB, 2023, week 4\n",
      "Downloading RB, 2023, week 5\n",
      "Downloading RB, 2023, week 6\n",
      "Downloading RB, 2023, week 7\n",
      "Downloading RB, 2023, week 8\n",
      "Downloading RB, 2023, week 9\n",
      "Downloading RB, 2023, week 10\n",
      "Downloading RB, 2023, week 11\n",
      "Downloading RB, 2023, week 12\n",
      "Downloading RB, 2023, week 13\n",
      "Downloading RB, 2023, week 14\n",
      "Downloading RB, 2023, week 15\n",
      "Downloading RB, 2023, week 16\n",
      "Downloading RB, 2023, week 17\n",
      "Downloading RB, 2023, week 18\n",
      "Downloading WR, 2020, week 1\n",
      "Downloading WR, 2020, week 2\n",
      "Downloading WR, 2020, week 3\n",
      "Downloading WR, 2020, week 4\n",
      "Downloading WR, 2020, week 5\n",
      "Downloading WR, 2020, week 6\n",
      "Downloading WR, 2020, week 7\n",
      "Downloading WR, 2020, week 8\n",
      "Downloading WR, 2020, week 9\n",
      "Downloading WR, 2020, week 10\n",
      "Downloading WR, 2020, week 11\n",
      "Downloading WR, 2020, week 12\n",
      "Downloading WR, 2020, week 13\n",
      "Downloading WR, 2020, week 14\n",
      "Downloading WR, 2020, week 15\n",
      "Downloading WR, 2020, week 16\n",
      "Downloading WR, 2020, week 17\n",
      "Downloading WR, 2020, week 18\n",
      "Downloading WR, 2021, week 1\n",
      "Downloading WR, 2021, week 2\n",
      "Downloading WR, 2021, week 3\n",
      "Downloading WR, 2021, week 4\n",
      "Downloading WR, 2021, week 5\n",
      "Downloading WR, 2021, week 6\n",
      "Downloading WR, 2021, week 7\n",
      "Downloading WR, 2021, week 8\n",
      "Downloading WR, 2021, week 9\n",
      "Downloading WR, 2021, week 10\n",
      "Downloading WR, 2021, week 11\n",
      "Downloading WR, 2021, week 12\n",
      "Downloading WR, 2021, week 13\n",
      "Downloading WR, 2021, week 14\n",
      "Downloading WR, 2021, week 15\n",
      "Downloading WR, 2021, week 16\n",
      "Downloading WR, 2021, week 17\n",
      "Downloading WR, 2021, week 18\n",
      "Downloading WR, 2022, week 1\n",
      "Downloading WR, 2022, week 2\n",
      "Downloading WR, 2022, week 3\n",
      "Downloading WR, 2022, week 4\n",
      "Downloading WR, 2022, week 5\n",
      "Downloading WR, 2022, week 6\n",
      "Downloading WR, 2022, week 7\n",
      "Downloading WR, 2022, week 8\n",
      "Downloading WR, 2022, week 9\n",
      "Downloading WR, 2022, week 10\n",
      "Downloading WR, 2022, week 11\n",
      "Downloading WR, 2022, week 12\n",
      "Downloading WR, 2022, week 13\n",
      "Downloading WR, 2022, week 14\n",
      "Downloading WR, 2022, week 15\n",
      "Downloading WR, 2022, week 16\n",
      "Downloading WR, 2022, week 17\n",
      "Downloading WR, 2022, week 18\n",
      "Downloading WR, 2023, week 1\n",
      "Downloading WR, 2023, week 2\n",
      "Downloading WR, 2023, week 3\n",
      "Downloading WR, 2023, week 4\n",
      "Downloading WR, 2023, week 5\n",
      "Downloading WR, 2023, week 6\n",
      "Downloading WR, 2023, week 7\n",
      "Downloading WR, 2023, week 8\n",
      "Downloading WR, 2023, week 9\n",
      "Downloading WR, 2023, week 10\n",
      "Downloading WR, 2023, week 11\n",
      "Downloading WR, 2023, week 12\n",
      "Downloading WR, 2023, week 13\n",
      "Downloading WR, 2023, week 14\n",
      "Downloading WR, 2023, week 15\n",
      "Downloading WR, 2023, week 16\n",
      "Downloading WR, 2023, week 17\n",
      "Downloading WR, 2023, week 18\n",
      "Downloading TE, 2020, week 1\n",
      "Downloading TE, 2020, week 2\n",
      "Downloading TE, 2020, week 3\n",
      "Downloading TE, 2020, week 4\n",
      "Downloading TE, 2020, week 5\n",
      "Downloading TE, 2020, week 6\n",
      "Downloading TE, 2020, week 7\n",
      "Downloading TE, 2020, week 8\n",
      "Downloading TE, 2020, week 9\n",
      "Downloading TE, 2020, week 10\n",
      "Downloading TE, 2020, week 11\n",
      "Downloading TE, 2020, week 12\n",
      "Downloading TE, 2020, week 13\n",
      "Downloading TE, 2020, week 14\n",
      "Downloading TE, 2020, week 15\n",
      "Downloading TE, 2020, week 16\n",
      "Downloading TE, 2020, week 17\n",
      "Downloading TE, 2020, week 18\n",
      "Downloading TE, 2021, week 1\n",
      "Downloading TE, 2021, week 2\n",
      "Downloading TE, 2021, week 3\n",
      "Downloading TE, 2021, week 4\n",
      "Downloading TE, 2021, week 5\n",
      "Downloading TE, 2021, week 6\n",
      "Downloading TE, 2021, week 7\n",
      "Downloading TE, 2021, week 8\n",
      "Downloading TE, 2021, week 9\n",
      "Downloading TE, 2021, week 10\n",
      "Downloading TE, 2021, week 11\n",
      "Downloading TE, 2021, week 12\n",
      "Downloading TE, 2021, week 13\n",
      "Downloading TE, 2021, week 14\n",
      "Downloading TE, 2021, week 15\n",
      "Downloading TE, 2021, week 16\n",
      "Downloading TE, 2021, week 17\n",
      "Downloading TE, 2021, week 18\n",
      "Downloading TE, 2022, week 1\n",
      "Downloading TE, 2022, week 2\n",
      "Downloading TE, 2022, week 3\n",
      "Downloading TE, 2022, week 4\n",
      "Downloading TE, 2022, week 5\n",
      "Downloading TE, 2022, week 6\n",
      "Downloading TE, 2022, week 7\n",
      "Downloading TE, 2022, week 8\n",
      "Downloading TE, 2022, week 9\n",
      "Downloading TE, 2022, week 10\n",
      "Downloading TE, 2022, week 11\n",
      "Downloading TE, 2022, week 12\n",
      "Downloading TE, 2022, week 13\n",
      "Downloading TE, 2022, week 14\n",
      "Downloading TE, 2022, week 15\n",
      "Downloading TE, 2022, week 16\n",
      "Downloading TE, 2022, week 17\n",
      "Downloading TE, 2022, week 18\n",
      "Downloading TE, 2023, week 1\n",
      "Downloading TE, 2023, week 2\n",
      "Downloading TE, 2023, week 3\n",
      "Downloading TE, 2023, week 4\n",
      "Downloading TE, 2023, week 5\n",
      "Downloading TE, 2023, week 6\n",
      "Downloading TE, 2023, week 7\n",
      "Downloading TE, 2023, week 8\n",
      "Downloading TE, 2023, week 9\n",
      "Downloading TE, 2023, week 10\n",
      "Downloading TE, 2023, week 11\n",
      "Downloading TE, 2023, week 12\n",
      "Downloading TE, 2023, week 13\n",
      "Downloading TE, 2023, week 14\n",
      "Downloading TE, 2023, week 15\n",
      "Downloading TE, 2023, week 16\n",
      "Downloading TE, 2023, week 17\n",
      "Downloading TE, 2023, week 18\n",
      "  Rank                Name   Age   Exp  G Cmp Att   Cm%  PYd  Y/Att  ...  \\\n",
      "0    1      Josh Allen BUF  24.0   3.0  1  33  46  71.7  312   6.78  ...   \n",
      "1    2  Russell Wilson SEA  32.0   9.0  1  31  35  88.6  322   9.20  ...   \n",
      "2    3    Aaron Rodgers GB  37.0  16.0  1  32  44  72.7  364   8.27  ...   \n",
      "3    4   Lamar Jackson BAL  23.0   3.0  1  20  25  80.0  275  11.00  ...   \n",
      "4    5    Kyler Murray ARI  23.0   2.0  1  26  40  65.0  230   5.75  ...   \n",
      "\n",
      "  FantPt Position Year  Week Scoring profile Y/Rsh  Rec  RecYd RecTD  Y/Rec  \n",
      "0   32.2        1   qb  2020               p   NaN  NaN    NaN   NaN    NaN  \n",
      "1   31.8        1   qb  2020               p   NaN  NaN    NaN   NaN    NaN  \n",
      "2   30.8        1   qb  2020               p   NaN  NaN    NaN   NaN    NaN  \n",
      "3   27.5        1   qb  2020               p   NaN  NaN    NaN   NaN    NaN  \n",
      "4   26.3        1   qb  2020               p   NaN  NaN    NaN   NaN    NaN  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# Main script to download data\n",
    "download_data = True  # Or False, depending on what you want to do\n",
    "\n",
    "if download_data is True:\n",
    "    positions = ['qb', 'rb', 'wr', 'te']\n",
    "    profile = 'p'\n",
    "    years = list(range(2020, 2024))\n",
    "    weeks = list(range(1, 19))\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for position, year, week in product(positions, years, weeks):\n",
    "        print(f'Downloading {position.upper()}, {year}, week {week}')\n",
    "        url = f'https://www.footballguys.com/playerhistoricalstats?pos={position}&yr={year}&startwk={week}&stopwk={week}&profile={profile}'\n",
    "        \n",
    "        # Get the HTML\n",
    "        html = download_url(url)\n",
    "        \n",
    "        # Parse the HTML\n",
    "        result = parse_html_table(html, position, year, week, profile)\n",
    "        \n",
    "        # Collect the result\n",
    "        results.append(result)\n",
    "\n",
    "        # Wait before downloading the next page\n",
    "        time.sleep(randrange(1, 5))\n",
    "\n",
    "    # Combine the week-by-week dataframes\n",
    "    data_df = pd.concat(results)\n",
    "\n",
    "elif download_data is False:\n",
    "    data_df = pd.read_parquet('../data/raw_qb_data.parquet')\n",
    "    print('Loaded data from file')\n",
    "\n",
    "# View the resulting DataFrame\n",
    "print(data_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fix the player name/team column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Age</th>\n",
       "      <th>Exp</th>\n",
       "      <th>G</th>\n",
       "      <th>Cmp</th>\n",
       "      <th>Att</th>\n",
       "      <th>Cm%</th>\n",
       "      <th>PYd</th>\n",
       "      <th>Y/Att</th>\n",
       "      <th>PTD</th>\n",
       "      <th>...</th>\n",
       "      <th>RshYd</th>\n",
       "      <th>RshTD</th>\n",
       "      <th>FP/G</th>\n",
       "      <th>FantPt</th>\n",
       "      <th>Week</th>\n",
       "      <th>Position</th>\n",
       "      <th>Year</th>\n",
       "      <th>Scoring profile</th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>78.3</td>\n",
       "      <td>232</td>\n",
       "      <td>10.09</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>33.2</td>\n",
       "      <td>33.2</td>\n",
       "      <td>1</td>\n",
       "      <td>qb</td>\n",
       "      <td>2024</td>\n",
       "      <td>p</td>\n",
       "      <td>Josh Allen</td>\n",
       "      <td>BUF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>80.0</td>\n",
       "      <td>289</td>\n",
       "      <td>9.63</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>29.7</td>\n",
       "      <td>29.7</td>\n",
       "      <td>1</td>\n",
       "      <td>qb</td>\n",
       "      <td>2024</td>\n",
       "      <td>p</td>\n",
       "      <td>Baker Mayfield</td>\n",
       "      <td>TB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>70.8</td>\n",
       "      <td>184</td>\n",
       "      <td>7.67</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>28.2</td>\n",
       "      <td>28.2</td>\n",
       "      <td>1</td>\n",
       "      <td>qb</td>\n",
       "      <td>2024</td>\n",
       "      <td>p</td>\n",
       "      <td>Jayden Daniels</td>\n",
       "      <td>WAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>41</td>\n",
       "      <td>63.4</td>\n",
       "      <td>273</td>\n",
       "      <td>6.66</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1</td>\n",
       "      <td>qb</td>\n",
       "      <td>2024</td>\n",
       "      <td>p</td>\n",
       "      <td>Lamar Jackson</td>\n",
       "      <td>BAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>47.4</td>\n",
       "      <td>212</td>\n",
       "      <td>11.16</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>26.1</td>\n",
       "      <td>26.1</td>\n",
       "      <td>1</td>\n",
       "      <td>qb</td>\n",
       "      <td>2024</td>\n",
       "      <td>p</td>\n",
       "      <td>Anthony Richardson</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank   Age  Exp  G Cmp Att   Cm%  PYd  Y/Att PTD  ... RshYd RshTD  FP/G  \\\n",
       "0    1  28.0  7.0  1  18  23  78.3  232  10.09   2  ...    39     2  33.2   \n",
       "1    2  29.0  7.0  1  24  30  80.0  289   9.63   4  ...    21     0  29.7   \n",
       "2    3  24.0  1.0  1  17  24  70.8  184   7.67   0  ...    88     2  28.2   \n",
       "3    4  27.0  7.0  1  26  41  63.4  273   6.66   1  ...   122     0  27.1   \n",
       "4    5  22.0  2.0  1   9  19  47.4  212  11.16   2  ...    56     1  26.1   \n",
       "\n",
       "  FantPt Week Position  Year Scoring profile              Player Team  \n",
       "0   33.2    1       qb  2024               p          Josh Allen  BUF  \n",
       "1   29.7    1       qb  2024               p      Baker Mayfield   TB  \n",
       "2   28.2    1       qb  2024               p      Jayden Daniels  WAS  \n",
       "3   27.1    1       qb  2024               p       Lamar Jackson  BAL  \n",
       "4   26.1    1       qb  2024               p  Anthony Richardson  IND  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = data_df.copy()\n",
    "test_df[['Player', 'Team']] = test_df['Name'].str.extract(r'^(.*?\\b(?:I{1,3}|IV)?)(?:\\s+)([A-Z]{2,3})$')\n",
    "test_df.drop(columns=['Name'], inplace=True)\n",
    "test_df.rename(columns={'Position': 'Week', 'Year': 'Position', 'Week': 'Year'}, inplace=True)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeam\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[43mdata_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mName\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m data_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mdata_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(x\u001b[38;5;241m.\u001b[39msplit()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m      3\u001b[0m data_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeam\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mdata_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      2\u001b[0m data_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mdata_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(x\u001b[38;5;241m.\u001b[39msplit()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m      3\u001b[0m data_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#data_df['Team']=data_df['Name'].apply(lambda x: x.split()[-1])\n",
    "#data_df['Name']=data_df['Name'].apply(lambda x: ' '.join(x.split()[:-1]))\n",
    "#data_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26324 entries, 0 to 26323\n",
      "Data columns (total 26 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Rank             26324 non-null  object\n",
      " 1   Name             26324 non-null  object\n",
      " 2   Age              26324 non-null  object\n",
      " 3   Exp              26324 non-null  object\n",
      " 4   G                26324 non-null  object\n",
      " 5   Cmp              2664 non-null   object\n",
      " 6   Att              2664 non-null   object\n",
      " 7   Cm%              2664 non-null   object\n",
      " 8   PYd              2664 non-null   object\n",
      " 9   Y/Att            2664 non-null   object\n",
      " 10  PTD              2664 non-null   object\n",
      " 11  Int              2664 non-null   object\n",
      " 12  Rsh              19841 non-null  object\n",
      " 13  RshYd            19841 non-null  object\n",
      " 14  RshTD            19841 non-null  object\n",
      " 15  FP/G             26324 non-null  object\n",
      " 16  FantPt           26324 non-null  object\n",
      " 17  Position         26324 non-null  int64 \n",
      " 18  Year             26324 non-null  object\n",
      " 19  Week             26324 non-null  int64 \n",
      " 20  Scoring profile  26324 non-null  object\n",
      " 21  Y/Rsh            6696 non-null   object\n",
      " 22  Rec              23660 non-null  object\n",
      " 23  RecYd            23660 non-null  object\n",
      " 24  RecTD            23660 non-null  object\n",
      " 25  Y/Rec            16964 non-null  object\n",
      "dtypes: int64(2), object(24)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# First, clean up the index and take a look at what we have:\n",
    "data_df.reset_index(inplace=True, drop=True)\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save as parquet\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdata_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/raw_qb_data.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/frame.py:3113\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[0;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m   3032\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3033\u001b[0m \u001b[38;5;124;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[1;32m   3034\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3109\u001b[0m \u001b[38;5;124;03m>>> content = f.read()\u001b[39;00m\n\u001b[1;32m   3110\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3111\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[0;32m-> 3113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3114\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3121\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3122\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/io/parquet.py:476\u001b[0m, in \u001b[0;36mto_parquet\u001b[0;34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(partition_cols, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    475\u001b[0m     partition_cols \u001b[38;5;241m=\u001b[39m [partition_cols]\n\u001b[0;32m--> 476\u001b[0m impl \u001b[38;5;241m=\u001b[39m \u001b[43mget_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    478\u001b[0m path_or_buf: FilePath \u001b[38;5;241m|\u001b[39m WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[1;32m    480\u001b[0m impl\u001b[38;5;241m.\u001b[39mwrite(\n\u001b[1;32m    481\u001b[0m     df,\n\u001b[1;32m    482\u001b[0m     path_or_buf,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/io/parquet.py:67\u001b[0m, in \u001b[0;36mget_engine\u001b[0;34m(engine)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m     65\u001b[0m             error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(err)\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to find a usable engine; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtried using: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfastparquet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA suitable version of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow or fastparquet is required for parquet \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupport.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to import the above resulted in these errors:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_msgs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m     )\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PyArrowImpl()\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "# Save as parquet\n",
    "data_df.to_parquet('../data/raw_qb_data.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
