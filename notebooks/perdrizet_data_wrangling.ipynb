{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling\n",
    "\n",
    "Since the data tables on the [Footballguys](https://www.footballguys.com/) website are fully rendered in HTML, we might be able to scrape the data without too much trouble. This gives us good control over exactly what data we download and an easy mechanism by which to update it throughout the season. Let's give it a try using [urllib](https://docs.python.org/3/howto/urllib2.html) and [BeautifulSoup](https://beautiful-soup-4.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import urllib.request\n",
    "from itertools import product\n",
    "from random import randrange\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download and parse HTML data\n",
    "\n",
    "The available data spans 1996 to 2024 and each year has 18 weeks of data. We also will want to download the data for multiple positions. But, let's start with just one. We also need to pick a scoring scheme, let's go with PPR. We can easily change this later. We will use a loop to construct and download the URL for each year and week and parse and collect the data as we get it.\n",
    "\n",
    "**Note**: Downloading all of the data for one position takes just over 45 minutes.\n",
    "\n",
    "### 1.1. Download function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_url(url: str) -> bytes:\n",
    "    '''Takes string url, downloads URL and returns HTML bytes object'''\n",
    "\n",
    "    headers={\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Host\": \"httpbin.io\",\n",
    "        \"Sec-Ch-Ua\": '\"Google Chrome\";v=\"131\", \"Chromium\";v=\"131\", \"Not_A Brand\";v=\"24\"',\n",
    "        \"Sec-Ch-Ua-Mobile\": \"?0\",\n",
    "        \"Sec-Ch-Ua-Platform\": '\"Linux\"',\n",
    "        \"Sec-Fetch-Dest\": \"document\",\n",
    "        \"Sec-Fetch-Mode\": \"navigate\",\n",
    "        \"Sec-Fetch-Site\": \"cross-site\",\n",
    "        \"Sec-Fetch-User\": \"?1\",\n",
    "        \"Upgrade-Insecure-Requests\": \"1\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    # Create the request\n",
    "    request_params = urllib.request.Request(\n",
    "        url=url,\n",
    "        headers=headers\n",
    "    )   \n",
    "\n",
    "    # Get the html\n",
    "    with urllib.request.urlopen(request_params) as response:\n",
    "        html=response.read()\n",
    "\n",
    "    return html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. HTML parsing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html_table(html: bytes, year: int, week: int, position: str, profile: str) -> pd.DataFrame:\n",
    "    '''Takes a html bytes object from URL, parses data table, adds\n",
    "    year, week, position and scoring profile and returns as pandas dataframe'''\n",
    "\n",
    "    # Extract the table rows\n",
    "    soup=BeautifulSoup(html, 'html.parser')\n",
    "    table=soup.find('table',{'class':'datasmall table'})\n",
    "    table_rows=table.find_all('tr')\n",
    "\n",
    "    # Get the column names from the first row\n",
    "    columns=table_rows[0].find_all('th')\n",
    "    column_names=[column.getText() for column in columns]\n",
    "    column_names.extend(['Position', 'Year', 'Week', 'Scoring profile'])\n",
    "\n",
    "    # Get the values for each row\n",
    "    data=[]\n",
    "\n",
    "    for row in table_rows[1:]:\n",
    "        columns=row.find_all('td')\n",
    "        values=[column.getText() for column in columns]\n",
    "        values.extend([position, year, week, profile])\n",
    "        data.append(values)\n",
    "\n",
    "    # Convert to pandas dataframe and return\n",
    "    return pd.DataFrame(columns=column_names, data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Main download loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1996, week 1\n",
      "Downloading 1996, week 2\n",
      "Downloading 1996, week 3\n",
      "Downloading 1996, week 4\n",
      "Downloading 1996, week 5\n",
      "Downloading 1996, week 6\n",
      "Downloading 1996, week 7\n",
      "Downloading 1996, week 8\n",
      "Downloading 1996, week 9\n",
      "Downloading 1996, week 10\n",
      "Downloading 1996, week 11\n",
      "Downloading 1996, week 12\n",
      "Downloading 1996, week 13\n",
      "Downloading 1996, week 14\n",
      "Downloading 1996, week 15\n",
      "Downloading 1996, week 16\n",
      "Downloading 1996, week 17\n",
      "Downloading 1996, week 18\n",
      "Downloading 1997, week 1\n",
      "Downloading 1997, week 2\n",
      "Downloading 1997, week 3\n",
      "Downloading 1997, week 4\n",
      "Downloading 1997, week 5\n",
      "Downloading 1997, week 6\n",
      "Downloading 1997, week 7\n",
      "Downloading 1997, week 8\n",
      "Downloading 1997, week 9\n",
      "Downloading 1997, week 10\n",
      "Downloading 1997, week 11\n",
      "Downloading 1997, week 12\n",
      "Downloading 1997, week 13\n",
      "Downloading 1997, week 14\n",
      "Downloading 1997, week 15\n",
      "Downloading 1997, week 16\n",
      "Downloading 1997, week 17\n",
      "Downloading 1997, week 18\n",
      "Downloading 1998, week 1\n",
      "Downloading 1998, week 2\n",
      "Downloading 1998, week 3\n",
      "Downloading 1998, week 4\n",
      "Downloading 1998, week 5\n",
      "Downloading 1998, week 6\n",
      "Downloading 1998, week 7\n",
      "Downloading 1998, week 8\n",
      "Downloading 1998, week 9\n",
      "Downloading 1998, week 10\n",
      "Downloading 1998, week 11\n",
      "Downloading 1998, week 12\n",
      "Downloading 1998, week 13\n",
      "Downloading 1998, week 14\n",
      "Downloading 1998, week 15\n",
      "Downloading 1998, week 16\n",
      "Downloading 1998, week 17\n",
      "Downloading 1998, week 18\n",
      "Downloading 1999, week 1\n",
      "Downloading 1999, week 2\n",
      "Downloading 1999, week 3\n",
      "Downloading 1999, week 4\n",
      "Downloading 1999, week 5\n",
      "Downloading 1999, week 6\n",
      "Downloading 1999, week 7\n",
      "Downloading 1999, week 8\n",
      "Downloading 1999, week 9\n",
      "Downloading 1999, week 10\n",
      "Downloading 1999, week 11\n",
      "Downloading 1999, week 12\n",
      "Downloading 1999, week 13\n",
      "Downloading 1999, week 14\n",
      "Downloading 1999, week 15\n",
      "Downloading 1999, week 16\n",
      "Downloading 1999, week 17\n",
      "Downloading 1999, week 18\n",
      "Downloading 2000, week 1\n",
      "Downloading 2000, week 2\n",
      "Downloading 2000, week 3\n",
      "Downloading 2000, week 4\n",
      "Downloading 2000, week 5\n",
      "Downloading 2000, week 6\n",
      "Downloading 2000, week 7\n",
      "Downloading 2000, week 8\n",
      "Downloading 2000, week 9\n",
      "Downloading 2000, week 10\n",
      "Downloading 2000, week 11\n",
      "Downloading 2000, week 12\n",
      "Downloading 2000, week 13\n",
      "Downloading 2000, week 14\n",
      "Downloading 2000, week 15\n",
      "Downloading 2000, week 16\n",
      "Downloading 2000, week 17\n",
      "Downloading 2000, week 18\n",
      "Downloading 2001, week 1\n",
      "Downloading 2001, week 2\n",
      "Downloading 2001, week 3\n",
      "Downloading 2001, week 4\n",
      "Downloading 2001, week 5\n",
      "Downloading 2001, week 6\n",
      "Downloading 2001, week 7\n",
      "Downloading 2001, week 8\n",
      "Downloading 2001, week 9\n",
      "Downloading 2001, week 10\n",
      "Downloading 2001, week 11\n",
      "Downloading 2001, week 12\n",
      "Downloading 2001, week 13\n",
      "Downloading 2001, week 14\n",
      "Downloading 2001, week 15\n",
      "Downloading 2001, week 16\n",
      "Downloading 2001, week 17\n",
      "Downloading 2001, week 18\n",
      "Downloading 2002, week 1\n",
      "Downloading 2002, week 2\n",
      "Downloading 2002, week 3\n",
      "Downloading 2002, week 4\n",
      "Downloading 2002, week 5\n",
      "Downloading 2002, week 6\n",
      "Downloading 2002, week 7\n",
      "Downloading 2002, week 8\n",
      "Downloading 2002, week 9\n",
      "Downloading 2002, week 10\n",
      "Downloading 2002, week 11\n",
      "Downloading 2002, week 12\n",
      "Downloading 2002, week 13\n",
      "Downloading 2002, week 14\n",
      "Downloading 2002, week 15\n",
      "Downloading 2002, week 16\n",
      "Downloading 2002, week 17\n",
      "Downloading 2002, week 18\n",
      "Downloading 2003, week 1\n",
      "Downloading 2003, week 2\n",
      "Downloading 2003, week 3\n",
      "Downloading 2003, week 4\n",
      "Downloading 2003, week 5\n",
      "Downloading 2003, week 6\n",
      "Downloading 2003, week 7\n",
      "Downloading 2003, week 8\n",
      "Downloading 2003, week 9\n",
      "Downloading 2003, week 10\n",
      "Downloading 2003, week 11\n",
      "Downloading 2003, week 12\n",
      "Downloading 2003, week 13\n",
      "Downloading 2003, week 14\n",
      "Downloading 2003, week 15\n",
      "Downloading 2003, week 16\n",
      "Downloading 2003, week 17\n",
      "Downloading 2003, week 18\n",
      "Downloading 2004, week 1\n",
      "Downloading 2004, week 2\n",
      "Downloading 2004, week 3\n",
      "Downloading 2004, week 4\n",
      "Downloading 2004, week 5\n",
      "Downloading 2004, week 6\n",
      "Downloading 2004, week 7\n",
      "Downloading 2004, week 8\n",
      "Downloading 2004, week 9\n",
      "Downloading 2004, week 10\n",
      "Downloading 2004, week 11\n",
      "Downloading 2004, week 12\n",
      "Downloading 2004, week 13\n",
      "Downloading 2004, week 14\n",
      "Downloading 2004, week 15\n",
      "Downloading 2004, week 16\n",
      "Downloading 2004, week 17\n",
      "Downloading 2004, week 18\n",
      "Downloading 2005, week 1\n",
      "Downloading 2005, week 2\n",
      "Downloading 2005, week 3\n",
      "Downloading 2005, week 4\n",
      "Downloading 2005, week 5\n",
      "Downloading 2005, week 6\n",
      "Downloading 2005, week 7\n",
      "Downloading 2005, week 8\n",
      "Downloading 2005, week 9\n",
      "Downloading 2005, week 10\n",
      "Downloading 2005, week 11\n",
      "Downloading 2005, week 12\n",
      "Downloading 2005, week 13\n",
      "Downloading 2005, week 14\n",
      "Downloading 2005, week 15\n",
      "Downloading 2005, week 16\n",
      "Downloading 2005, week 17\n",
      "Downloading 2005, week 18\n",
      "Downloading 2006, week 1\n",
      "Downloading 2006, week 2\n",
      "Downloading 2006, week 3\n",
      "Downloading 2006, week 4\n",
      "Downloading 2006, week 5\n",
      "Downloading 2006, week 6\n",
      "Downloading 2006, week 7\n",
      "Downloading 2006, week 8\n",
      "Downloading 2006, week 9\n",
      "Downloading 2006, week 10\n",
      "Downloading 2006, week 11\n",
      "Downloading 2006, week 12\n",
      "Downloading 2006, week 13\n",
      "Downloading 2006, week 14\n",
      "Downloading 2006, week 15\n",
      "Downloading 2006, week 16\n",
      "Downloading 2006, week 17\n",
      "Downloading 2006, week 18\n",
      "Downloading 2007, week 1\n",
      "Downloading 2007, week 2\n",
      "Downloading 2007, week 3\n",
      "Downloading 2007, week 4\n",
      "Downloading 2007, week 5\n",
      "Downloading 2007, week 6\n",
      "Downloading 2007, week 7\n",
      "Downloading 2007, week 8\n",
      "Downloading 2007, week 9\n",
      "Downloading 2007, week 10\n",
      "Downloading 2007, week 11\n",
      "Downloading 2007, week 12\n",
      "Downloading 2007, week 13\n",
      "Downloading 2007, week 14\n",
      "Downloading 2007, week 15\n",
      "Downloading 2007, week 16\n",
      "Downloading 2007, week 17\n",
      "Downloading 2007, week 18\n",
      "Downloading 2008, week 1\n",
      "Downloading 2008, week 2\n",
      "Downloading 2008, week 3\n",
      "Downloading 2008, week 4\n",
      "Downloading 2008, week 5\n",
      "Downloading 2008, week 6\n",
      "Downloading 2008, week 7\n",
      "Downloading 2008, week 8\n",
      "Downloading 2008, week 9\n",
      "Downloading 2008, week 10\n",
      "Downloading 2008, week 11\n",
      "Downloading 2008, week 12\n",
      "Downloading 2008, week 13\n",
      "Downloading 2008, week 14\n",
      "Downloading 2008, week 15\n",
      "Downloading 2008, week 16\n",
      "Downloading 2008, week 17\n",
      "Downloading 2008, week 18\n",
      "Downloading 2009, week 1\n",
      "Downloading 2009, week 2\n",
      "Downloading 2009, week 3\n",
      "Downloading 2009, week 4\n",
      "Downloading 2009, week 5\n",
      "Downloading 2009, week 6\n",
      "Downloading 2009, week 7\n",
      "Downloading 2009, week 8\n",
      "Downloading 2009, week 9\n",
      "Downloading 2009, week 10\n",
      "Downloading 2009, week 11\n",
      "Downloading 2009, week 12\n",
      "Downloading 2009, week 13\n",
      "Downloading 2009, week 14\n",
      "Downloading 2009, week 15\n",
      "Downloading 2009, week 16\n",
      "Downloading 2009, week 17\n",
      "Downloading 2009, week 18\n",
      "Downloading 2010, week 1\n",
      "Downloading 2010, week 2\n",
      "Downloading 2010, week 3\n",
      "Downloading 2010, week 4\n",
      "Downloading 2010, week 5\n",
      "Downloading 2010, week 6\n",
      "Downloading 2010, week 7\n",
      "Downloading 2010, week 8\n",
      "Downloading 2010, week 9\n",
      "Downloading 2010, week 10\n",
      "Downloading 2010, week 11\n",
      "Downloading 2010, week 12\n",
      "Downloading 2010, week 13\n",
      "Downloading 2010, week 14\n",
      "Downloading 2010, week 15\n",
      "Downloading 2010, week 16\n",
      "Downloading 2010, week 17\n",
      "Downloading 2010, week 18\n",
      "Downloading 2011, week 1\n",
      "Downloading 2011, week 2\n",
      "Downloading 2011, week 3\n",
      "Downloading 2011, week 4\n",
      "Downloading 2011, week 5\n",
      "Downloading 2011, week 6\n",
      "Downloading 2011, week 7\n",
      "Downloading 2011, week 8\n",
      "Downloading 2011, week 9\n",
      "Downloading 2011, week 10\n",
      "Downloading 2011, week 11\n",
      "Downloading 2011, week 12\n",
      "Downloading 2011, week 13\n",
      "Downloading 2011, week 14\n",
      "Downloading 2011, week 15\n",
      "Downloading 2011, week 16\n",
      "Downloading 2011, week 17\n",
      "Downloading 2011, week 18\n",
      "Downloading 2012, week 1\n",
      "Downloading 2012, week 2\n",
      "Downloading 2012, week 3\n",
      "Downloading 2012, week 4\n",
      "Downloading 2012, week 5\n",
      "Downloading 2012, week 6\n",
      "Downloading 2012, week 7\n",
      "Downloading 2012, week 8\n",
      "Downloading 2012, week 9\n",
      "Downloading 2012, week 10\n",
      "Downloading 2012, week 11\n",
      "Downloading 2012, week 12\n",
      "Downloading 2012, week 13\n",
      "Downloading 2012, week 14\n",
      "Downloading 2012, week 15\n",
      "Downloading 2012, week 16\n",
      "Downloading 2012, week 17\n",
      "Downloading 2012, week 18\n",
      "Downloading 2013, week 1\n",
      "Downloading 2013, week 2\n",
      "Downloading 2013, week 3\n",
      "Downloading 2013, week 4\n",
      "Downloading 2013, week 5\n",
      "Downloading 2013, week 6\n",
      "Downloading 2013, week 7\n",
      "Downloading 2013, week 8\n",
      "Downloading 2013, week 9\n",
      "Downloading 2013, week 10\n",
      "Downloading 2013, week 11\n",
      "Downloading 2013, week 12\n",
      "Downloading 2013, week 13\n",
      "Downloading 2013, week 14\n",
      "Downloading 2013, week 15\n",
      "Downloading 2013, week 16\n",
      "Downloading 2013, week 17\n",
      "Downloading 2013, week 18\n",
      "Downloading 2014, week 1\n",
      "Downloading 2014, week 2\n",
      "Downloading 2014, week 3\n",
      "Downloading 2014, week 4\n",
      "Downloading 2014, week 5\n",
      "Downloading 2014, week 6\n",
      "Downloading 2014, week 7\n",
      "Downloading 2014, week 8\n",
      "Downloading 2014, week 9\n",
      "Downloading 2014, week 10\n",
      "Downloading 2014, week 11\n",
      "Downloading 2014, week 12\n",
      "Downloading 2014, week 13\n",
      "Downloading 2014, week 14\n",
      "Downloading 2014, week 15\n",
      "Downloading 2014, week 16\n",
      "Downloading 2014, week 17\n",
      "Downloading 2014, week 18\n",
      "Downloading 2015, week 1\n",
      "Downloading 2015, week 2\n",
      "Downloading 2015, week 3\n",
      "Downloading 2015, week 4\n",
      "Downloading 2015, week 5\n",
      "Downloading 2015, week 6\n",
      "Downloading 2015, week 7\n",
      "Downloading 2015, week 8\n",
      "Downloading 2015, week 9\n",
      "Downloading 2015, week 10\n",
      "Downloading 2015, week 11\n",
      "Downloading 2015, week 12\n",
      "Downloading 2015, week 13\n",
      "Downloading 2015, week 14\n",
      "Downloading 2015, week 15\n",
      "Downloading 2015, week 16\n",
      "Downloading 2015, week 17\n",
      "Downloading 2015, week 18\n",
      "Downloading 2016, week 1\n",
      "Downloading 2016, week 2\n",
      "Downloading 2016, week 3\n",
      "Downloading 2016, week 4\n",
      "Downloading 2016, week 5\n",
      "Downloading 2016, week 6\n",
      "Downloading 2016, week 7\n",
      "Downloading 2016, week 8\n",
      "Downloading 2016, week 9\n",
      "Downloading 2016, week 10\n",
      "Downloading 2016, week 11\n",
      "Downloading 2016, week 12\n",
      "Downloading 2016, week 13\n",
      "Downloading 2016, week 14\n",
      "Downloading 2016, week 15\n",
      "Downloading 2016, week 16\n",
      "Downloading 2016, week 17\n",
      "Downloading 2016, week 18\n",
      "Downloading 2017, week 1\n",
      "Downloading 2017, week 2\n",
      "Downloading 2017, week 3\n",
      "Downloading 2017, week 4\n",
      "Downloading 2017, week 5\n",
      "Downloading 2017, week 6\n",
      "Downloading 2017, week 7\n",
      "Downloading 2017, week 8\n",
      "Downloading 2017, week 9\n",
      "Downloading 2017, week 10\n",
      "Downloading 2017, week 11\n",
      "Downloading 2017, week 12\n",
      "Downloading 2017, week 13\n",
      "Downloading 2017, week 14\n",
      "Downloading 2017, week 15\n",
      "Downloading 2017, week 16\n",
      "Downloading 2017, week 17\n",
      "Downloading 2017, week 18\n",
      "Downloading 2018, week 1\n",
      "Downloading 2018, week 2\n",
      "Downloading 2018, week 3\n",
      "Downloading 2018, week 4\n",
      "Downloading 2018, week 5\n",
      "Downloading 2018, week 6\n",
      "Downloading 2018, week 7\n",
      "Downloading 2018, week 8\n",
      "Downloading 2018, week 9\n",
      "Downloading 2018, week 10\n",
      "Downloading 2018, week 11\n",
      "Downloading 2018, week 12\n",
      "Downloading 2018, week 13\n",
      "Downloading 2018, week 14\n",
      "Downloading 2018, week 15\n",
      "Downloading 2018, week 16\n",
      "Downloading 2018, week 17\n",
      "Downloading 2018, week 18\n",
      "Downloading 2019, week 1\n",
      "Downloading 2019, week 2\n",
      "Downloading 2019, week 3\n",
      "Downloading 2019, week 4\n",
      "Downloading 2019, week 5\n",
      "Downloading 2019, week 6\n",
      "Downloading 2019, week 7\n",
      "Downloading 2019, week 8\n",
      "Downloading 2019, week 9\n",
      "Downloading 2019, week 10\n",
      "Downloading 2019, week 11\n",
      "Downloading 2019, week 12\n",
      "Downloading 2019, week 13\n",
      "Downloading 2019, week 14\n",
      "Downloading 2019, week 15\n",
      "Downloading 2019, week 16\n",
      "Downloading 2019, week 17\n",
      "Downloading 2019, week 18\n",
      "Downloading 2020, week 1\n",
      "Downloading 2020, week 2\n",
      "Downloading 2020, week 3\n",
      "Downloading 2020, week 4\n",
      "Downloading 2020, week 5\n",
      "Downloading 2020, week 6\n",
      "Downloading 2020, week 7\n",
      "Downloading 2020, week 8\n",
      "Downloading 2020, week 9\n",
      "Downloading 2020, week 10\n",
      "Downloading 2020, week 11\n",
      "Downloading 2020, week 12\n",
      "Downloading 2020, week 13\n",
      "Downloading 2020, week 14\n",
      "Downloading 2020, week 15\n",
      "Downloading 2020, week 16\n",
      "Downloading 2020, week 17\n",
      "Downloading 2020, week 18\n",
      "Downloading 2021, week 1\n",
      "Downloading 2021, week 2\n",
      "Downloading 2021, week 3\n",
      "Downloading 2021, week 4\n",
      "Downloading 2021, week 5\n",
      "Downloading 2021, week 6\n",
      "Downloading 2021, week 7\n",
      "Downloading 2021, week 8\n",
      "Downloading 2021, week 9\n",
      "Downloading 2021, week 10\n",
      "Downloading 2021, week 11\n",
      "Downloading 2021, week 12\n",
      "Downloading 2021, week 13\n",
      "Downloading 2021, week 14\n",
      "Downloading 2021, week 15\n",
      "Downloading 2021, week 16\n",
      "Downloading 2021, week 17\n",
      "Downloading 2021, week 18\n",
      "Downloading 2022, week 1\n",
      "Downloading 2022, week 2\n",
      "Downloading 2022, week 3\n",
      "Downloading 2022, week 4\n",
      "Downloading 2022, week 5\n",
      "Downloading 2022, week 6\n",
      "Downloading 2022, week 7\n",
      "Downloading 2022, week 8\n",
      "Downloading 2022, week 9\n",
      "Downloading 2022, week 10\n",
      "Downloading 2022, week 11\n",
      "Downloading 2022, week 12\n",
      "Downloading 2022, week 13\n",
      "Downloading 2022, week 14\n",
      "Downloading 2022, week 15\n",
      "Downloading 2022, week 16\n",
      "Downloading 2022, week 17\n",
      "Downloading 2022, week 18\n",
      "Downloading 2023, week 1\n",
      "Downloading 2023, week 2\n",
      "Downloading 2023, week 3\n",
      "Downloading 2023, week 4\n",
      "Downloading 2023, week 5\n",
      "Downloading 2023, week 6\n",
      "Downloading 2023, week 7\n",
      "Downloading 2023, week 8\n",
      "Downloading 2023, week 9\n",
      "Downloading 2023, week 10\n",
      "Downloading 2023, week 11\n",
      "Downloading 2023, week 12\n",
      "Downloading 2023, week 13\n",
      "Downloading 2023, week 14\n",
      "Downloading 2023, week 15\n",
      "Downloading 2023, week 16\n",
      "Downloading 2023, week 17\n",
      "Downloading 2023, week 18\n",
      "Downloading 2024, week 1\n",
      "Downloading 2024, week 2\n",
      "Downloading 2024, week 3\n",
      "Downloading 2024, week 4\n",
      "Downloading 2024, week 5\n",
      "Downloading 2024, week 6\n",
      "Downloading 2024, week 7\n",
      "Downloading 2024, week 8\n",
      "Downloading 2024, week 9\n",
      "Downloading 2024, week 10\n",
      "Downloading 2024, week 11\n",
      "Downloading 2024, week 12\n",
      "Downloading 2024, week 13\n",
      "Downloading 2024, week 14\n",
      "Downloading 2024, week 15\n",
      "Downloading 2024, week 16\n",
      "Downloading 2024, week 17\n",
      "Downloading 2024, week 18\n"
     ]
    }
   ],
   "source": [
    "# URL parameter arguments\n",
    "position='qb'\n",
    "profile='p'\n",
    "years=list(range(1996,2025))\n",
    "weeks=list(range(1,19))\n",
    "\n",
    "# Empty list to accumulate results\n",
    "results=[]\n",
    "\n",
    "for year, week in product(years, weeks):\n",
    "\n",
    "    print(f'Downloading {year}, week {week}')\n",
    "\n",
    "    # Construct the URL for this year and week\n",
    "    url=f'https://www.footballguys.com/playerhistoricalstats?pos={position}&yr={year}&startwk={week}&stopwk={week}&profile={profile}'\n",
    "\n",
    "    # Get the HTML\n",
    "    html=download_url(url)\n",
    "\n",
    "    # Parse the HTML\n",
    "    result=parse_html_table(html, position, year, week, profile)\n",
    "\n",
    "    # Collect the result\n",
    "    results.append(result)\n",
    "\n",
    "    # Wait before downloading the next page\n",
    "    time.sleep(randrange(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the week by week dataframes\n",
    "data_df=pd.concat(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fix the player name/team column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Exp</th>\n",
       "      <th>G</th>\n",
       "      <th>Cmp</th>\n",
       "      <th>Att</th>\n",
       "      <th>Cm%</th>\n",
       "      <th>PYd</th>\n",
       "      <th>Y/Att</th>\n",
       "      <th>...</th>\n",
       "      <th>Rsh</th>\n",
       "      <th>RshYd</th>\n",
       "      <th>RshTD</th>\n",
       "      <th>FP/G</th>\n",
       "      <th>FantPt</th>\n",
       "      <th>Position</th>\n",
       "      <th>Year</th>\n",
       "      <th>Week</th>\n",
       "      <th>Scoring profile</th>\n",
       "      <th>Team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Brett Favre</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>74.1</td>\n",
       "      <td>247</td>\n",
       "      <td>9.15</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>qb</td>\n",
       "      <td>1996</td>\n",
       "      <td>p</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mark Brunell</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>64.5</td>\n",
       "      <td>212</td>\n",
       "      <td>6.84</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.6</td>\n",
       "      <td>1</td>\n",
       "      <td>qb</td>\n",
       "      <td>1996</td>\n",
       "      <td>p</td>\n",
       "      <td>JAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Vinny Testaverde</td>\n",
       "      <td>33.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>33</td>\n",
       "      <td>57.6</td>\n",
       "      <td>254</td>\n",
       "      <td>7.70</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>20.4</td>\n",
       "      <td>1</td>\n",
       "      <td>qb</td>\n",
       "      <td>1996</td>\n",
       "      <td>p</td>\n",
       "      <td>BAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Rodney Peete</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>34</td>\n",
       "      <td>58.8</td>\n",
       "      <td>269</td>\n",
       "      <td>7.91</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>17.8</td>\n",
       "      <td>1</td>\n",
       "      <td>qb</td>\n",
       "      <td>1996</td>\n",
       "      <td>p</td>\n",
       "      <td>PHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Kerry Collins</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>31</td>\n",
       "      <td>54.8</td>\n",
       "      <td>198</td>\n",
       "      <td>6.39</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>17.3</td>\n",
       "      <td>1</td>\n",
       "      <td>qb</td>\n",
       "      <td>1996</td>\n",
       "      <td>p</td>\n",
       "      <td>CAR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank              Name   Age   Exp  G Cmp Att   Cm%  PYd Y/Att  ... Rsh  \\\n",
       "0    1       Brett Favre  27.0   6.0  1  20  27  74.1  247  9.15  ...   1   \n",
       "1    2      Mark Brunell  26.0   3.0  1  20  31  64.5  212  6.84  ...  10   \n",
       "2    3  Vinny Testaverde  33.0  10.0  1  19  33  57.6  254  7.70  ...   8   \n",
       "3    4      Rodney Peete  30.0   8.0  1  20  34  58.8  269  7.91  ...   6   \n",
       "4    5     Kerry Collins  24.0   2.0  1  17  31  54.8  198  6.39  ...   1   \n",
       "\n",
       "  RshYd RshTD  FP/G FantPt Position Year  Week Scoring profile Team  \n",
       "0     1     0  26.0   26.0        1   qb  1996               p   GB  \n",
       "1    41     0  20.6   20.6        1   qb  1996               p  JAX  \n",
       "2    42     1  20.4   20.4        1   qb  1996               p  BAL  \n",
       "3    10     0  17.8   17.8        1   qb  1996               p  PHI  \n",
       "4    14     0  17.3   17.3        1   qb  1996               p  CAR  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['Team']=data_df['Name'].apply(lambda x: x.split()[-1])\n",
    "data_df['Name']=data_df['Name'].apply(lambda x: ' '.join(x.split()[:-1]))\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17938 entries, 0 to 17937\n",
      "Data columns (total 22 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Rank             17938 non-null  object\n",
      " 1   Name             17938 non-null  object\n",
      " 2   Age              17938 non-null  object\n",
      " 3   Exp              17938 non-null  object\n",
      " 4   G                17938 non-null  object\n",
      " 5   Cmp              17938 non-null  object\n",
      " 6   Att              17938 non-null  object\n",
      " 7   Cm%              17938 non-null  object\n",
      " 8   PYd              17938 non-null  object\n",
      " 9   Y/Att            17938 non-null  object\n",
      " 10  PTD              17938 non-null  object\n",
      " 11  Int              17938 non-null  object\n",
      " 12  Rsh              17938 non-null  object\n",
      " 13  RshYd            17938 non-null  object\n",
      " 14  RshTD            17938 non-null  object\n",
      " 15  FP/G             17938 non-null  object\n",
      " 16  FantPt           17938 non-null  object\n",
      " 17  Position         17938 non-null  object\n",
      " 18  Year             17938 non-null  object\n",
      " 19  Week             17938 non-null  object\n",
      " 20  Scoring profile  17938 non-null  object\n",
      " 21  Team             17938 non-null  object\n",
      "dtypes: object(22)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# First, clean up the index and take a look at what we have:\n",
    "data_df.reset_index(inplace=True, drop=True)\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as parquet\n",
    "data_df.to_parquet('../data/raw_qb_data.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
