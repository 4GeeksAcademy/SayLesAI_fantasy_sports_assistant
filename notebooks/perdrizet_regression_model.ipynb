{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression model\n",
    "\n",
    "First, let's try a regression model. We can use a few weeks of stats for a given player as input, and try to predict the next week's stats as the output. To get an estimate of model performance we can make predictions for all of the players in all of the years and/or even break up each season into batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "from typing import Tuple\n",
    "\n",
    "# PyPI imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "# Input data\n",
    "data_file='../data/parsed_qb_data.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 17938 entries, (np.int64(1996), 'Brett Favre', np.int64(1)) to (np.int64(2024), 'Drake Maye', np.int64(18))\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Rank    17938 non-null  object\n",
      " 1   Exp     17938 non-null  object\n",
      " 2   G       17938 non-null  object\n",
      " 3   Cmp     17938 non-null  object\n",
      " 4   Att     17938 non-null  object\n",
      " 5   Cm%     17938 non-null  object\n",
      " 6   PYd     17938 non-null  object\n",
      " 7   Y/Att   17938 non-null  object\n",
      " 8   PTD     17938 non-null  object\n",
      " 9   Int     17938 non-null  object\n",
      " 10  Rsh     17938 non-null  object\n",
      " 11  RshYd   17938 non-null  object\n",
      " 12  RshTD   17938 non-null  object\n",
      " 13  FP/G    17938 non-null  object\n",
      " 14  FantPt  17938 non-null  object\n",
      "dtypes: object(15)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data_df=pd.read_parquet(data_file)\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data cleaning\n",
    "\n",
    "Next, we need to set the datatype for our features and then standardize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace empty strings with NAN\n",
    "data_df.replace('', pd.NA, inplace=True)\n",
    "\n",
    "# Drop NAN containing rows\n",
    "data_df.dropna(inplace=True)\n",
    "\n",
    "# Set float dtype for all features\n",
    "data_df=data_df.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data generator function\n",
    "\n",
    "To test model performance we need a function to yield batches of data for regression modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(data_df: pd.DataFrame, input_window: int) -> Tuple[np.array, np.array]:\n",
    "    '''Takes dataframe, input window size, parses data into feature label pairs,\n",
    "    returns as tuple of numpy arrays'''\n",
    "\n",
    "    # Get list of seasons\n",
    "    seasons=data_df.index.get_level_values('Season').unique().tolist()\n",
    "\n",
    "    features=[]\n",
    "    labels=[]\n",
    "\n",
    "    # Loop on seasons\n",
    "    for season in seasons:\n",
    "\n",
    "        # Extract the data for this season\n",
    "        season_df=data_df.loc[(season)]\n",
    "        \n",
    "        # Get the list of player for this season\n",
    "        players=season_df.index.get_level_values('Player').unique().tolist()\n",
    "\n",
    "        # loop on the players\n",
    "        for player in players:\n",
    "\n",
    "            # Extract the data for this player\n",
    "            player_df=season_df.loc[(player)]\n",
    "\n",
    "            # Indexing variable for batch\n",
    "            input_start_index=0\n",
    "\n",
    "            # Loop on the player data\n",
    "            while input_start_index + input_window + 1 < len(player_df):\n",
    "\n",
    "                # Extract and collect the features and labels\n",
    "                feature_row=player_df.iloc[input_start_index:input_start_index + input_window]\n",
    "                label_row=player_df.iloc[input_start_index + input_window]\n",
    "                features.append(feature_row.values.tolist())\n",
    "                labels.append(label_row.values.tolist())\n",
    "\n",
    "                # Update the index\n",
    "                input_start_index+=input_window + 1\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    features=np.array(features)\n",
    "    labels=np.array(labels)\n",
    "\n",
    "    # Squeeze out the extra dimension for window width of 1\n",
    "    if input_window == 1:\n",
    "        features=features.squeeze(axis=1)\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training/testing data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: (5256, 15)\n",
      "Labels: (5256, 15)\n"
     ]
    }
   ],
   "source": [
    "# Generate some feature, label pairs\n",
    "input_window=1\n",
    "features, labels=generate_data(data_df, input_window)\n",
    "\n",
    "# Split them into training and validation\n",
    "training_features, testing_features, training_labels, testing_labels=train_test_split(features, labels)\n",
    "\n",
    "# Scale the data\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(training_features)\n",
    "training_features=scaler.transform(training_features)\n",
    "training_labels=scaler.transform(training_labels)\n",
    "testing_features=scaler.transform(testing_features)\n",
    "testing_labels=scaler.transform(testing_labels)\n",
    "\n",
    "print(f'Features: {training_features.shape}')\n",
    "print(f'Labels: {training_labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Multiple linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on the training data and make predictions\n",
    "# for the testing data\n",
    "model=LinearRegression().fit(training_features, training_labels)\n",
    "predictions=model.predict(testing_features)\n",
    "\n",
    "# Un-scale the predictions and testing labels\n",
    "testing_labels=scaler.inverse_transform(testing_labels)\n",
    "predictions=scaler.inverse_transform(predictions)\n",
    "\n",
    "# Calculate feature-wise RMSE\n",
    "for feature, i in zip(data_df.columns, range(testing_labels.shape[1])):\n",
    "    rmse=root_mean_squared_error(predictions[:,i], testing_labels[:,i])\n",
    "    print(f'{feature} RMSE: {rmse}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
